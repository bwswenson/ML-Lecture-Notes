\babel@toc {english}{}\relax 
\contentsline {chapter}{\numberline {1}Calculus and Analysis For Machine Learning}{5}{chapter.1}%
\contentsline {chapter}{\numberline {2}Least Squares and Linear Regression}{7}{chapter.2}%
\contentsline {section}{\numberline {2.1}Least Squares: Linear Algebra Perspective}{7}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Standard Least Squares: $m>n$}{7}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Other case: $m<n$}{8}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Least Squares and the Pseudo Inverse}{8}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}Gauss-Markov Theorem: Least Squares and MLE}{9}{section.2.2}%
\contentsline {section}{\numberline {2.3}Ridge Regression}{9}{section.2.3}%
\contentsline {section}{\numberline {2.4}LASSO and Elastic Nets}{9}{section.2.4}%
\contentsline {section}{\numberline {2.5}Bayesian Linear Regression}{9}{section.2.5}%
\contentsline {section}{\numberline {2.6}LASSO}{11}{section.2.6}%
\contentsline {chapter}{\numberline {3}PCA}{13}{chapter.3}%
\contentsline {section}{\numberline {3.1}Introduction}{13}{section.3.1}%
\contentsline {section}{\numberline {3.2}PCA: Maximum Variance Perspective}{14}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Digression: Lagrange Multipliers}{14}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Return from digression}{15}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}PCA: Minimum Reconstruction Loss Perspective}{17}{section.3.3}%
\contentsline {section}{\numberline {3.4}Interpreting PCA}{17}{section.3.4}%
\contentsline {section}{\numberline {3.5}Examples}{18}{section.3.5}%
\contentsline {section}{\numberline {3.6}Unifying max variance and min reconstruction loss perspectives}{18}{section.3.6}%
\contentsline {section}{\numberline {3.7}PCA and the Singular Value Decomposition}{18}{section.3.7}%
\contentsline {section}{\numberline {3.8}Kernel PCA}{19}{section.3.8}%
\contentsline {chapter}{\numberline {4}Other fun topics/one off topics}{21}{chapter.4}%
\contentsline {chapter}{\numberline {5}Other notes/Daily notes}{23}{chapter.5}%
\contentsline {section}{\numberline {5.1}Gaussian Distribution: Normalizing Constant 5/24/24}{23}{section.5.1}%
\contentsline {section}{\numberline {5.2}Polar Change of Coordinates}{23}{section.5.2}%
\contentsline {section}{\numberline {5.3}Change of Variables}{24}{section.5.3}%
\contentsline {subsubsection}{Building Intuition}{29}{section*.7}%
\contentsline {section}{\numberline {5.4}High dimensional spaces}{31}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Volume of $d$-ball}{31}{subsection.5.4.1}%
\contentsline {subsection}{\numberline {5.4.2}Balls and Cubes}{32}{subsection.5.4.2}%
\contentsline {subsection}{\numberline {5.4.3}Most of the mass is near the equator}{32}{subsection.5.4.3}%
\contentsline {subsection}{\numberline {5.4.4}Most of the volume is near the surface}{33}{subsection.5.4.4}%
\contentsline {subsection}{\numberline {5.4.5}High dimensional cubes}{33}{subsection.5.4.5}%
\contentsline {subsection}{\numberline {5.4.6}Distances between randomly sampled points}{33}{subsection.5.4.6}%
\contentsline {subsection}{\numberline {5.4.7}Digression: Lp balls}{34}{subsection.5.4.7}%
\contentsline {subsection}{\numberline {5.4.8}Discussion}{34}{subsection.5.4.8}%
\contentsline {section}{\numberline {5.5}High Dimensional Gaussian }{34}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}Radial density of Gaussian}{34}{subsection.5.5.1}%
